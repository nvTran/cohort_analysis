{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTIONS:\n",
    "# Click on run cell button on every single cell\n",
    "# After running this cell\n",
    "# CLICK THE URL PROVIDED BY THE CODE OUTPUT, PASTE THE STRING  TO THE TEXTBOX AND PRESS ENTER\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# You can change some variables in selected cells so that you can generate custom reports.\n",
    "# Skip this if you don't want to know how this is set up this way\n",
    "# Since Colab runs on a range of IPs whenever we connect to runtimes, we are only to connect to our Cloud SQL database by using proxy\n",
    "# We apt install screen because when we run the proxy starts, it has to stay active to listen to incoming connections, the other cells in the book can't start running. \n",
    "# So the screen will keep our proxy running in the background, and we can connect to our Cloud SQL to retrieve data.\n",
    "\n",
    "\n",
    "# Import all modules required and install missing ones\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from operator import attrgetter\n",
    "import matplotlib.colors as mcolors\n",
    "!wget https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64 -O cloud_sql_proxy --quiet\n",
    "!mkdir -p /cloudsql\n",
    "!chmod +x cloud_sql_proxy --quiet\n",
    "!pip install git+https://github.com/GoogleCloudPlatform/cloud-sql-python-connector --quiet\n",
    "\n",
    "from google.cloud.sql.connector import connector\n",
    "!apt -qq update && apt -qq install  -y   screen\n",
    "\n",
    "\n",
    "# Authenticate your connection by your work email\n",
    "# CLICK THE URL PROVIDED BY THE CODE OUTPUT, PASTE THE STRING  TO THE TEXTBOX AND PRESS ENTER\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to Cloud SQL proxy and let it run in the background with screen\n",
    "!screen -S test -d -m \"./projectid:region:dbname--dir /cloudsql\"\n",
    "from pymysql import*\n",
    "import xlwt\n",
    "import pandas.io.sql as sql\n",
    "\n",
    "# Connection settings, you can change the db instance here\n",
    "con = connector.connect(\n",
    "    \"#projectid:region:dbname\", \n",
    "    \"pymysql\",\n",
    "    user=\"\",\n",
    "    password=\"\",\n",
    "    db=\"\"\n",
    ")\n",
    "\n",
    "# This is the actually query that will be run. You can change the created_at timeframe or order_status_label, etc\n",
    "raw_data =sql.read_sql(\"SELECT user_id, payment_at, grand_total, id FROM ### WHERE ####\",con)\n",
    "# have a sneak peek at the raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data type of a column to float\n",
    "raw_data['grand_total'] = raw_data['grand_total'].astype(float)\n",
    "\n",
    "\n",
    "# Choose a dataframe that we want to make cohort analysis\n",
    "# df = with_phone_number.copy()\n",
    "\n",
    "df_users = raw_data.copy()\n",
    "df_orders = raw_data.copy()\n",
    "df_gmv = raw_data.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create cohort_pivot for df_users to get number of unique customers retentions\n",
    "# Create order_month column from created_at column\n",
    "df_users['order_month'] = df_users['created_at'].dt.to_period('M')\n",
    "\n",
    "# Create cohort column based on the first month of user_id activity\n",
    "df_users['cohort'] = df_users.groupby('user_id')['created_at'].transform('min').dt.to_period('M') \n",
    "# Create another dataframe that contain number of unique numbers of customers for different order_month based on cohort\n",
    "df_users_cohort = df_users.groupby(['cohort', 'order_month']).agg(n_customers=('user_id', 'nunique')).reset_index(drop=False)\n",
    "print(df_users_cohort)\n",
    "\n",
    "# Transform the df_cohort dataframe to cohort_pivot table\n",
    "df_users_cohort['period_number'] = (df_users_cohort.order_month - df_users_cohort.cohort).apply(attrgetter('n'))\n",
    "cohort_pivot_users = df_users_cohort.pivot_table(index = 'cohort', columns = 'period_number', values = 'n_customers')\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create cohort_pivot for df_gmv to get total gmv retentions\n",
    "# Create order_month column from created_at column\n",
    "df_gmv['order_month'] = df_gmv['created_at'].dt.to_period('M')\n",
    "\n",
    "# Create cohort column based on the first month of user_id activity\n",
    "df_gmv['cohort'] = df_gmv.groupby('user_id')['created_at'].transform('min').dt.to_period('M') \n",
    "# Create another dataframe that contain total gmv for different order_month based on cohort\n",
    "df_gmv_cohort = df_gmv.groupby(['cohort', 'order_month']).agg(gmv=('grand_total', 'sum')).reset_index(drop=False)\n",
    "\n",
    "print(df_gmv_cohort)\n",
    "# Transform the df_cohort dataframe to cohort_pivot table\n",
    "df_gmv_cohort['period_number'] = (df_gmv_cohort.order_month - df_gmv_cohort.cohort).apply(attrgetter('n'))\n",
    "cohort_pivot_gmv = df_gmv_cohort.pivot_table(index = 'cohort',columns = 'period_number', values = 'gmv')\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Create cohort_pivot for df_orders to get total orders retentions\n",
    "# Create order_month column from created_at column\n",
    "df_orders['order_month'] = df_orders['created_at'].dt.to_period('M')\n",
    "\n",
    "# Create cohort column based on the first month of user_id activity\n",
    "df_orders['cohort'] = df_orders.groupby('user_id')['created_at'].transform('min').dt.to_period('M') \n",
    "\n",
    "# Create another dataframe that contain number of orders for different order_month based on cohort\n",
    "df_orders_cohort = df_orders.groupby(['cohort', 'order_month']).agg(orders=('user_id', 'count')).reset_index(drop=False)\n",
    "print(df_orders_cohort)\n",
    "# Transform the df_cohort dataframe to cohort_pivot table\n",
    "df_orders_cohort['period_number'] = (df_orders_cohort.order_month - df_orders_cohort.cohort).apply(attrgetter('n'))\n",
    "cohort_pivot_orders = df_orders_cohort.pivot_table(index = 'cohort', columns = 'period_number', values = 'orders')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is final cohort analysis image that you can copy and paste\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# CREATE COHORT ANALYSIS FOR ACTIVE BUYERS RETENTION\n",
    "# Create retention matrix based on cohort_pivot dataframe, basically converting customer number to percentage\n",
    "cohort_size_users = cohort_pivot_users.iloc[:,0]\n",
    "retention_matrix_users = cohort_pivot_users.divide(cohort_size_users, axis = 0)\n",
    "\n",
    "# Visualize the retention_matrix \n",
    "with sns.axes_style(\"white\"):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 12), sharey=True, gridspec_kw={'width_ratios': [1, 11]})\n",
    "    \n",
    "    # retention matrix\n",
    "    sns.heatmap(retention_matrix_users, \n",
    "                mask=retention_matrix_users.isnull(), \n",
    "                annot=True, \n",
    "                fmt='.0%', \n",
    "                cmap='YlGnBu', \n",
    "                ax=ax[1])\n",
    "    ax[1].set_title('Active Users Retention: % of returned buyers over subsequent months', fontsize=16)\n",
    "    ax[1].set(xlabel='# of periods',\n",
    "              ylabel='')\n",
    "\n",
    "    # cohort size\n",
    "    cohort_size_users = pd.DataFrame(cohort_size_users).rename(columns={0: 'Users'})\n",
    "    white_cmap = mcolors.ListedColormap(['white'])\n",
    "    sns.heatmap(cohort_size_users, \n",
    "                annot=True, \n",
    "                cbar=False, \n",
    "                fmt='g', \n",
    "                cmap=\"Purples\", \n",
    "                ax=ax[0])\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig('CA_users.png')\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# CREATE COHORT ANALYSIS FOR ORDERS RETENTION\n",
    "# Create retention matrix based on cohort_pivot dataframe, basically converting customer number to percentage\n",
    "cohort_size_orders = cohort_pivot_orders.iloc[:,0]\n",
    "retention_matrix_orders = cohort_pivot_orders.divide(cohort_size_orders, axis = 0)\n",
    "\n",
    "# Visualize the retention_matrix \n",
    "with sns.axes_style(\"white\"):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 12), sharey=True, gridspec_kw={'width_ratios': [1, 11]})\n",
    "    \n",
    "    # retention matrix\n",
    "    sns.heatmap(retention_matrix_orders, \n",
    "                mask=retention_matrix_orders.isnull(), \n",
    "                annot=True, \n",
    "                fmt='.0%', \n",
    "                cmap='YlGnBu', \n",
    "                ax=ax[1])\n",
    "    ax[1].set_title('Orders Retention', fontsize=16)\n",
    "    ax[1].set(xlabel='# of periods',\n",
    "              ylabel='')\n",
    "\n",
    "    # cohort size\n",
    "    cohort_size_orders = pd.DataFrame(cohort_size_orders).rename(columns={0: 'Orders'})\n",
    "    white_cmap = mcolors.ListedColormap(['white'])\n",
    "    sns.heatmap(cohort_size_orders, \n",
    "                annot=True, \n",
    "                cbar=False, \n",
    "                fmt='g', \n",
    "                cmap=\"Purples\", \n",
    "                ax=ax[0])\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig('CA_orders.png')\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# CREATE COHORT ANALYSIS FOR GMV RETENTION\n",
    "# Create retention matrix based on cohort_pivot dataframe, basically converting customer number to percentage\n",
    "cohort_size_gmv = cohort_pivot_gmv.iloc[:,0]\n",
    "retention_matrix_gmv = cohort_pivot_gmv.divide(cohort_size_gmv, axis = 0)\n",
    "\n",
    "# Visualize the retention_matrix \n",
    "with sns.axes_style(\"white\"):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 12), sharey=True, gridspec_kw={'width_ratios': [1, 11]})\n",
    "    \n",
    "    # retention matrix\n",
    "    sns.heatmap(retention_matrix_gmv, \n",
    "                mask=retention_matrix_gmv.isnull(), \n",
    "                annot=True, \n",
    "                fmt='.0%', \n",
    "                cmap='YlGnBu', \n",
    "                ax=ax[1])\n",
    "    ax[1].set_title('GMV Retention', fontsize=16)\n",
    "    ax[1].set(xlabel='# of periods',\n",
    "              ylabel='')\n",
    "\n",
    "    # cohort size\n",
    "    cohort_size_gmv = pd.DataFrame(cohort_size_gmv).rename(columns={0: 'GMV $'})\n",
    "    white_cmap = mcolors.ListedColormap(['white'])\n",
    "    sns.heatmap(cohort_size_gmv, \n",
    "                annot=True, \n",
    "                cbar=False, \n",
    "                fmt='g', \n",
    "                cmap=\"Purples\", \n",
    "                ax=ax[0])\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.savefig('CA_gmv.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Google Sheets\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "! pip3 install --quiet gspread==3.6.0\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import gspread\n",
    "\n",
    "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "# Export users cohort analysis\n",
    "\n",
    "retention_matrix_users_flattened = pd.DataFrame(cohort_pivot_users.to_records())\n",
    "\n",
    "# Convert cohort data type from Period to string. This is because datetime format is not JSON serialization which is unable to be uploaded to Google Sheets\n",
    "retention_matrix_users_flattened['cohort']=retention_matrix_users_flattened['cohort'].astype(str)\n",
    "\n",
    "# cohort_pivot['cohort'].astype(str)\n",
    "retention_matrix_users_flattened.fillna('', inplace=True)\n",
    "\n",
    "spreadsheet = gc.open(\"marketplace metrics\")\n",
    "current_worksheet = spreadsheet.worksheet('CA_users')\n",
    "current_worksheet.update([retention_matrix_users_flattened.columns.values.tolist()] + retention_matrix_users_flattened.values.tolist())\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "# Export orders cohort analysis\n",
    "retention_matrix_orders_flattened = pd.DataFrame(cohort_pivot_orders.to_records())\n",
    "\n",
    "# Convert cohort data type from Period to string. This is because datetime format is not JSON serialization which is unable to be uploaded to Google Sheets\n",
    "retention_matrix_orders_flattened['cohort']=retention_matrix_orders_flattened['cohort'].astype(str)\n",
    "\n",
    "# cohort_pivot['cohort'].astype(str)\n",
    "retention_matrix_orders_flattened.fillna('', inplace=True)\n",
    "\n",
    "spreadsheet = gc.open(\"marketplace metrics\")\n",
    "current_worksheet = spreadsheet.worksheet('CA_orders')\n",
    "current_worksheet.update([retention_matrix_orders_flattened.columns.values.tolist()] + retention_matrix_orders_flattened.values.tolist())\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "# Export gmv cohort analysis\n",
    "\n",
    "retention_matrix_gmv_flattened = pd.DataFrame(cohort_pivot_gmv.to_records())\n",
    "\n",
    "# Convert cohort data type from Period to string. This is because datetime format is not JSON serialization which is unable to be uploaded to Google Sheets\n",
    "retention_matrix_gmv_flattened['cohort']=retention_matrix_gmv_flattened['cohort'].astype(str)\n",
    "\n",
    "# cohort_pivot['cohort'].astype(str)\n",
    "retention_matrix_gmv_flattened.fillna('', inplace=True)\n",
    "\n",
    "spreadsheet = gc.open(\"marketplace metrics\")\n",
    "current_worksheet = spreadsheet.worksheet('CA_gmv')\n",
    "current_worksheet.update([retention_matrix_gmv_flattened.columns.values.tolist()] + retention_matrix_gmv_flattened.values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# kill proxy by closing screen\n",
    "!screen -X -S test quit\n",
    "\n",
    "# This is the end of this notebook\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
